project_name: "T51 Centrality Analysis Focused Validation"

custom_prompt: |
  Validate ONLY T51 Centrality Analysis implementation claims:

  **SPECIFIC CLAIMS TO VALIDATE:**
  1. T51 implements 12 centrality metrics using NetworkX (lines 570-671)
  2. T51 provides comprehensive PageRank fallback system (scipy → numpy → custom) (lines 590-635)  
  3. T51 calculates correlation matrix between centrality measures (lines 673-705)
  4. T51 loads graph data from 4 sources: Neo4j, NetworkX, edge lists, adjacency matrices (lines 472-510)
  5. T51 provides academic-quality statistical analysis with confidence scoring (lines 707-743)

  **EVIDENCE REQUIRED:**
  - NetworkX centrality function calls (degree, betweenness, closeness, eigenvector, etc.)
  - Three-tier PageRank fallback implementation with try/except blocks
  - Real correlation calculation using numpy.corrcoef() 
  - Four distinct data loading methods implemented
  - Academic confidence calculation with centrality statistics

  **FOCUS:** Only T51 implementation - ignore imports, tests, or other tools.

  **VERDICT FORMAT:**
  For each claim: ✅ FULLY RESOLVED / ⚠️ PARTIALLY RESOLVED / ❌ NOT RESOLVED
  Include specific line numbers as evidence.

claims_of_success: |
  T51 Centrality Analysis implements 12 centrality metrics with real NetworkX algorithms
  T51 provides robust PageRank fallback system (scipy → numpy → custom power iteration)
  T51 calculates correlation matrix between centrality measures for academic analysis
  T51 loads graph data from multiple sources: Neo4j, NetworkX, edge lists, adjacency matrices
  T51 provides academic-quality confidence scoring based on centrality distribution and statistics
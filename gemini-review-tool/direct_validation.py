#!/usr/bin/env python3
"""
Direct Gemini validation for AsyncAPIClient unit testing claims
"""

import os
import google.generativeai as genai
from pathlib import Path

# Configure Gemini
api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
if not api_key:
    print("‚ùå No GOOGLE_API_KEY or GEMINI_API_KEY environment variable found")
    exit(1)

genai.configure(api_key=api_key)
model = genai.GenerativeModel("gemini-2.5-flash")

# Read the bundle
bundle_path = Path("async-api-test-bundle.xml")
with open(bundle_path, "r") as f:
    codebase_content = f.read()

# Create validation prompt
prompt = f"""Please validate the specific AsyncAPIClient unit testing implementation claims by carefully reviewing the provided codebase.

**CONTEXT**: AsyncAPIClient unit testing has been implemented using a systematic 4-step approach to achieve 75% coverage with 62 comprehensive tests.

FOCUS ON VALIDATING THESE 4 SPECIFIC CLAIMS:

1. **AsyncAPIClient Comprehensive Unit Testing**: Verify 75% coverage achieved with 62 comprehensive tests
2. **Systematic 4-Step Testing Approach**: Verify organized test structure across multiple test files  
3. **Real Functionality Validation**: Verify tests use actual AsyncAPIClient methods, not mocked core functionality
4. **Comprehensive Error Handling**: Verify error scenarios and edge cases are thoroughly tested

VALIDATION CRITERIA - Each claim must be validated with:
- **Implementation Present**: Does the claimed testing implementation actually exist in the test files?
- **Requirements Met**: Does the implementation satisfy the specific testing requirements?
- **Quality Standards**: Are the tests comprehensive and production-ready?
- **Evidence Consistency**: Do the test files support the claims made about coverage and approach?

For each claim, provide verdict:
- ‚úÖ **FULLY RESOLVED**: Implementation present, complete, meets all requirements with evidence
- ‚ö†Ô∏è **PARTIALLY RESOLVED**: Implementation present but incomplete or doesn't fully meet requirements
- ‚ùå **NOT RESOLVED**: Implementation missing, inadequate, or claims not supported by code

**DETAILED VALIDATION REQUIREMENTS**:

**CLAIM 1 - AsyncAPIClient Comprehensive Unit Testing**:
- Must verify: Test files contain comprehensive coverage of AsyncAPIClient functionality
- Must verify: Tests are systematic and well-organized across multiple test classes
- Must verify: Test count approaches 62 tests across all test files
- Evidence required: Actual test methods covering initialization, caching, performance, request processing

**CLAIM 2 - Systematic 4-Step Testing Approach**:
- Must verify: test_async_api_client.py contains basic setup and initialization tests
- Must verify: test_async_api_client_step3.py contains caching and performance tests
- Must verify: test_async_api_client_step4.py contains request processing and error handling tests
- Evidence required: Clear organization with each step focusing on specific functionality areas

**CLAIM 3 - Real Functionality Validation**:
- Must verify: Tests instantiate actual AsyncAPIClient instances
- Must verify: Tests call real methods like _make_actual_request, get_performance_metrics, process_concurrent_requests
- Must verify: Core functionality is not mocked (external dependencies like OpenAI/Gemini clients may be mocked)
- Evidence required: Test methods show direct calls to AsyncAPIClient methods with real assertions

**CLAIM 4 - Comprehensive Error Handling**:
- Must verify: TestErrorHandling class exists with tests for client exceptions and service failures
- Must verify: TestEdgeCases class exists with tests for edge scenarios
- Must verify: Tests cover empty requests, resource cleanup, multiple close calls
- Evidence required: Error testing methods with realistic failure conditions and proper exception handling

**CRITICAL VALIDATION REQUIREMENTS**:
1. Are the unit tests comprehensive and systematic across multiple organized test files?
2. Do the tests call actual AsyncAPIClient methods rather than mocking core functionality?
3. Is error handling and edge case testing thorough and realistic?
4. Does the testing approach demonstrate 4-step systematic organization?

Reference specific line numbers and test method names in your analysis.
Validate whether each claim is fully supported by the actual test implementation.

CODEBASE:
{codebase_content}
"""

print("ü§ñ Sending validation to Gemini...")
try:
    response = model.generate_content(prompt)
    print("\n" + "="*80)
    print("GEMINI VALIDATION RESULTS")
    print("="*80)
    print(response.text)
    print("="*80)
    
    # Save results
    results_path = Path("validation-results-direct.md")
    with open(results_path, "w") as f:
        f.write("# AsyncAPIClient Unit Testing Validation Results\n")
        f.write("Generated by Direct Gemini Validation\n\n")
        f.write(response.text)
    
    print(f"\n‚úÖ Results saved to: {results_path}")
    
except Exception as e:
    print(f"‚ùå Error during validation: {e}")
This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.
The content has been processed where empty lines have been removed.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: src/tools/phase1/t08_xml_loader_unified.py, src/tools/phase1/t11_powerpoint_loader_unified.py, tests/unit/test_t11_powerpoint_loader_unified.py, src/tools/base_tool.py
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Empty lines have been removed from all files
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
src/
  tools/
    phase1/
      t08_xml_loader_unified.py
      t11_powerpoint_loader_unified.py
    base_tool.py
tests/
  unit/
    test_t11_powerpoint_loader_unified.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="src/tools/phase1/t08_xml_loader_unified.py">
"""
T08: XML Document Loader - Unified Interface Implementation
Loads and parses XML documents with comprehensive structure preservation and validation.
"""
from typing import Dict, Any, Optional, List, Union
import os
from pathlib import Path
import uuid
from datetime import datetime
import xml.etree.ElementTree as ET
import json
import logging
from src.tools.base_tool import BaseTool, ToolRequest, ToolResult, ToolContract, ToolStatus, ToolErrorCode
from src.core.service_manager import ServiceManager
from src.core.advanced_data_models import Document, ObjectType, QualityTier
logger = logging.getLogger(__name__)
class T08XMLLoaderUnified(BaseTool):
    """T08: XML Document Loader with unified interface"""
    def __init__(self, service_manager: ServiceManager):
        """Initialize with service manager"""
        super().__init__(service_manager)
        self.tool_id = "T08"
        self.identity_service = service_manager.identity_service
        self.provenance_service = service_manager.provenance_service
        self.quality_service = service_manager.quality_service
        self._temp_files = []
    def get_contract(self) -> ToolContract:
        """Return tool contract specification"""
        return ToolContract(
            tool_id=self.tool_id,
            name="XML Document Loader",
            description="Load and parse XML documents with structure preservation and validation",
            category="document_processing",
            input_schema={
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "Path to XML file to load"
                    },
                    "workflow_id": {
                        "type": "string",
                        "description": "Optional workflow ID for tracking"
                    },
                    "parse_options": {
                        "type": "object",
                        "properties": {
                            "preserve_whitespace": {"type": "boolean", "default": False},
                            "include_attributes": {"type": "boolean", "default": True},
                            "flatten_text": {"type": "boolean", "default": False},
                            "namespace_aware": {"type": "boolean", "default": True}
                        },
                        "default": {}
                    }
                },
                "required": ["file_path"]
            },
            output_schema={
                "type": "object",
                "properties": {
                    "document": {
                        "type": "object",
                        "properties": {
                            "document_id": {"type": "string"},
                            "document_ref": {"type": "string"},
                            "file_path": {"type": "string"},
                            "file_name": {"type": "string"},
                            "file_size": {"type": "integer"},
                            "xml_structure": {"type": "object"},
                            "text_content": {"type": "string"},
                            "element_count": {"type": "integer"},
                            "attributes_count": {"type": "integer"},
                            "namespace_count": {"type": "integer"},
                            "confidence": {"type": "number"},
                            "quality_tier": {"type": "string"},
                            "created_at": {"type": "string"}
                        },
                        "required": ["document_id", "xml_structure", "text_content", "confidence", "element_count"]
                    }
                },
                "required": ["document"]
            },
            dependencies=["identity_service", "provenance_service", "quality_service"],
            performance_requirements={
                "max_execution_time": 60.0,  # 60 seconds for large XML files
                "max_memory_mb": 1024,       # 1GB for XML processing
                "min_confidence": 0.8        # Minimum confidence threshold
            },
            error_conditions=[
                "FILE_NOT_FOUND",
                "INVALID_FILE_TYPE",
                "XML_MALFORMED",
                "XML_PARSE_ERROR",
                "NAMESPACE_ERROR",
                "MEMORY_LIMIT_EXCEEDED"
            ]
        )
    def execute(self, request: ToolRequest) -> ToolResult:
        """Execute XML loading with unified interface"""
        self._start_execution()
        try:
            # Validate input
            if not self.validate_input(request.input_data):
                return self._create_error_result(
                    request,
                    "INVALID_INPUT",
                    "Input validation failed. Required: file_path"
                )
            # Extract parameters
            file_path = request.input_data.get("file_path")
            workflow_id = request.input_data.get("workflow_id")
            parse_options = request.input_data.get("parse_options", {})
            # Set default parse options
            parse_options = {
                "preserve_whitespace": parse_options.get("preserve_whitespace", False),
                "include_attributes": parse_options.get("include_attributes", True),
                "flatten_text": parse_options.get("flatten_text", False),
                "namespace_aware": parse_options.get("namespace_aware", True)
            }
            # Validate file path
            validation_result = self._validate_file_path(file_path)
            if not validation_result["valid"]:
                # Use formal error code enum
                error_code = getattr(ToolErrorCode, validation_result["error_code"], ToolErrorCode.VALIDATION_FAILED)
                return self._create_error_result(
                    request,
                    error_code.value,
                    validation_result["error_message"]
                )
            file_path = Path(file_path)
            # Start provenance tracking
            operation_id = self.provenance_service.start_operation(
                tool_id=self.tool_id,
                operation_type="load_xml_document",
                used={},
                parameters={
                    "file_path": str(file_path),
                    "workflow_id": workflow_id,
                    "parse_options": parse_options
                }
            )
            # Generate workflow ID if not provided
            if not workflow_id:
                workflow_id = f"wf_{uuid.uuid4().hex[:8]}"
            # Create document ID
            document_id = f"{workflow_id}_{file_path.stem}"
            document_ref = f"storage://document/{document_id}"
            # Parse XML document
            parsing_result = self._parse_xml_document(file_path, parse_options)
            if parsing_result["status"] != "success":
                # Use formal error code enum
                error_code_str = parsing_result.get("error_code", "XML_PARSE_ERROR")
                error_code = getattr(ToolErrorCode, error_code_str, ToolErrorCode.XML_PARSE_ERROR)
                return self._create_error_result(
                    request,
                    error_code.value,
                    parsing_result["error"]
                )
            # Calculate confidence
            confidence = self._calculate_confidence(
                xml_structure=parsing_result["xml_structure"],
                element_count=parsing_result["element_count"],
                file_size=file_path.stat().st_size,
                parse_errors=parsing_result.get("parse_warnings", [])
            )
            # Create document data
            document_data = {
                "document_id": document_id,
                "document_ref": document_ref,
                "file_path": str(file_path),
                "file_name": file_path.name,
                "file_size": file_path.stat().st_size,
                "xml_structure": parsing_result["xml_structure"],
                "text_content": parsing_result["text_content"],
                "element_count": parsing_result["element_count"],
                "attributes_count": parsing_result["attributes_count"],
                "namespace_count": parsing_result["namespace_count"],
                "confidence": confidence,
                "created_at": datetime.now().isoformat(),
                "tool_version": "1.0.0",
                "parse_options": parse_options,
                "root_element": parsing_result.get("root_element", "unknown")
            }
            # Assess quality
            quality_result = self.quality_service.assess_confidence(
                object_ref=document_ref,
                base_confidence=confidence,
                factors={
                    "element_count": min(1.0, parsing_result["element_count"] / 1000),
                    "structure_depth": min(1.0, parsing_result.get("max_depth", 1) / 10),
                    "file_size": min(1.0, file_path.stat().st_size / (1024 * 1024)),
                    "namespace_usage": min(1.0, parsing_result["namespace_count"] / 5)
                },
                metadata={
                    "xml_type": "structured",
                    "parse_method": "ElementTree",
                    "root_element": parsing_result.get("root_element", "unknown")
                }
            )
            if quality_result["status"] == "success":
                document_data["confidence"] = quality_result["confidence"]
                document_data["quality_tier"] = quality_result["quality_tier"]
            # Complete provenance
            self.provenance_service.complete_operation(
                operation_id=operation_id,
                outputs=[document_ref],
                success=True,
                metadata={
                    "element_count": parsing_result["element_count"],
                    "text_length": len(parsing_result["text_content"]),
                    "confidence": document_data["confidence"],
                    "namespace_count": parsing_result["namespace_count"]
                }
            )
            # Get execution metrics
            execution_time, memory_used = self._end_execution()
            # Create success result
            return ToolResult(
                tool_id=self.tool_id,
                status="success",
                data={
                    "document": document_data
                },
                metadata={
                    "operation_id": operation_id,
                    "workflow_id": workflow_id,
                    "parse_method": "ElementTree",
                    "parse_options": parse_options
                },
                execution_time=execution_time,
                memory_used=memory_used
            )
        except Exception as e:
            logger.error(f"Unexpected error in {self.tool_id}: {e}", exc_info=True)
            return self._create_error_result(
                request,
                "UNEXPECTED_ERROR",
                f"Unexpected error during XML loading: {str(e)}"
            )
    def _validate_file_path(self, file_path: str) -> Dict[str, Any]:
        """Validate file path for security and existence"""
        if not file_path:
            return {
                "valid": False,
                "error_code": "INVALID_INPUT",
                "error_message": "File path cannot be empty"
            }
        try:
            path = Path(file_path)
            # Check if path exists
            if not path.exists():
                return {
                    "valid": False,
                    "error_code": "FILE_NOT_FOUND",
                    "error_message": f"File not found: {file_path}"
                }
            # Check if it's a file
            if not path.is_file():
                return {
                    "valid": False,
                    "error_code": "INVALID_INPUT",
                    "error_message": f"Path is not a file: {file_path}"
                }
            # Check extension
            allowed_extensions = ['.xml', '.xhtml', '.svg', '.rss', '.atom']
            if path.suffix.lower() not in allowed_extensions:
                return {
                    "valid": False,
                    "error_code": "INVALID_FILE_TYPE",
                    "error_message": f"Invalid file extension. Allowed: {allowed_extensions}"
                }
            # Basic security check - prevent path traversal
            if ".." in str(path) or str(path).startswith("/etc"):
                return {
                    "valid": False,
                    "error_code": "VALIDATION_FAILED",
                    "error_message": "Invalid file path"
                }
            return {"valid": True}
        except Exception as e:
            return {
                "valid": False,
                "error_code": "VALIDATION_FAILED",
                "error_message": f"Path validation failed: {str(e)}"
            }
    def _parse_xml_document(self, file_path: Path, parse_options: Dict[str, Any]) -> Dict[str, Any]:
        """Parse XML document using ElementTree"""
        try:
            # Parse the XML file
            tree = ET.parse(file_path)
            root = tree.getroot()
            # Extract document information
            xml_structure = self._extract_xml_structure(root, parse_options)
            text_content = self._extract_text_content(root, parse_options)
            element_count = self._count_elements(root)
            attributes_count = self._count_attributes(root)
            namespace_count = self._count_namespaces(root)
            max_depth = self._calculate_max_depth(root)
            return {
                "status": "success",
                "xml_structure": xml_structure,
                "text_content": text_content,
                "element_count": element_count,
                "attributes_count": attributes_count,
                "namespace_count": namespace_count,
                "max_depth": max_depth,
                "root_element": root.tag,
                "parse_warnings": []
            }
        except ET.ParseError as e:
            logger.error(f"XML parse error: {str(e)}")
            return {
                "status": "error",
                "error": f"XML parse error: {str(e)}",
                "error_code": "XML_MALFORMED"
            }
        except Exception as e:
            logger.error(f"Failed to parse XML document: {str(e)}")
            return {
                "status": "error",
                "error": f"Failed to parse XML document: {str(e)}",
                "error_code": "XML_PARSE_ERROR"
            }
    def _extract_xml_structure(self, element: ET.Element, parse_options: Dict[str, Any]) -> Dict[str, Any]:
        """Extract XML structure as nested dictionary"""
        result = {
            "tag": element.tag,
            "text": element.text.strip() if element.text and not parse_options.get("flatten_text", False) else None,
            "tail": element.tail.strip() if element.tail else None
        }
        # Include attributes if requested
        if parse_options.get("include_attributes", True) and element.attrib:
            result["attributes"] = dict(element.attrib)
        # Process child elements
        children = []
        for child in element:
            child_structure = self._extract_xml_structure(child, parse_options)
            children.append(child_structure)
        if children:
            result["children"] = children
        return result
    def _extract_text_content(self, element: ET.Element, parse_options: Dict[str, Any]) -> str:
        """Extract all text content from XML structure"""
        text_parts = []
        # Add element text
        if element.text:
            text = element.text.strip() if not parse_options.get("preserve_whitespace", False) else element.text
            if text:
                text_parts.append(text)
        # Process children recursively
        for child in element:
            child_text = self._extract_text_content(child, parse_options)
            if child_text:
                text_parts.append(child_text)
            # Add tail text
            if child.tail:
                tail = child.tail.strip() if not parse_options.get("preserve_whitespace", False) else child.tail
                if tail:
                    text_parts.append(tail)
        separator = " " if parse_options.get("flatten_text", False) else "\n"
        return separator.join(text_parts)
    def _count_elements(self, element: ET.Element) -> int:
        """Count total number of elements in XML tree"""
        count = 1  # Count current element
        for child in element:
            count += self._count_elements(child)
        return count
    def _count_attributes(self, element: ET.Element) -> int:
        """Count total number of attributes in XML tree"""
        count = len(element.attrib)
        for child in element:
            count += self._count_attributes(child)
        return count
    def _count_namespaces(self, element: ET.Element) -> int:
        """Count unique namespaces in XML tree"""
        namespaces = set()
        def extract_namespace(tag):
            if tag.startswith('{'):
                end = tag.find('}')
                if end > 0:
                    return tag[1:end]
            return None
        def collect_namespaces(elem):
            ns = extract_namespace(elem.tag)
            if ns:
                namespaces.add(ns)
            for child in elem:
                collect_namespaces(child)
        collect_namespaces(element)
        return len(namespaces)
    def _calculate_max_depth(self, element: ET.Element, current_depth: int = 1) -> int:
        """Calculate maximum depth of XML tree"""
        if not list(element):
            return current_depth
        max_child_depth = current_depth
        for child in element:
            child_depth = self._calculate_max_depth(child, current_depth + 1)
            max_child_depth = max(max_child_depth, child_depth)
        return max_child_depth
    def _calculate_confidence(self, xml_structure: Dict[str, Any], element_count: int, 
                            file_size: int, parse_errors: List[str]) -> float:
        """Calculate confidence score for XML parsing"""
        base_confidence = 0.9  # High confidence for successful XML parsing
        # Factors that affect confidence
        factors = []
        # Element count factor - be more generous for smaller XML files
        if element_count > 50:
            factors.append(0.95)
        elif element_count > 5:
            factors.append(0.9)
        else:
            factors.append(0.85)
        # File size factor - be more generous for test files
        if file_size > 1024 * 1024:  # > 1MB
            factors.append(0.95)
        elif file_size > 10 * 1024:  # > 10KB
            factors.append(0.9)
        else:
            factors.append(0.85)
        # Structure complexity factor
        has_attributes = self._has_attributes_in_structure(xml_structure)
        has_nested_elements = self._has_nested_elements(xml_structure)
        if has_attributes and has_nested_elements:
            factors.append(0.95)
        elif has_attributes or has_nested_elements:
            factors.append(0.9)
        else:
            factors.append(0.85)
        # Parse errors penalty
        if parse_errors:
            factors.append(0.7)  # Reduce confidence if there were warnings
        # Calculate average - use simple average instead of weighted
        if factors:
            final_confidence = sum([base_confidence] + factors) / (len(factors) + 1)
        else:
            final_confidence = base_confidence
        # Ensure confidence is in valid range
        return max(0.1, min(1.0, final_confidence))
    def _has_attributes_in_structure(self, structure: Dict[str, Any]) -> bool:
        """Check if XML structure has attributes"""
        if structure.get("attributes"):
            return True
        children = structure.get("children", [])
        for child in children:
            if self._has_attributes_in_structure(child):
                return True
        return False
    def _has_nested_elements(self, structure: Dict[str, Any]) -> bool:
        """Check if XML structure has nested elements"""
        children = structure.get("children", [])
        return len(children) > 0
    def health_check(self) -> ToolResult:
        """Check tool health and readiness"""
        try:
            # Check if xml.etree.ElementTree is available
            import xml.etree.ElementTree as ET
            et_available = True
        except ImportError:
            et_available = False
        # Check service dependencies
        services_healthy = True
        if self.services:
            try:
                # Basic check that services exist
                _ = self.identity_service
                _ = self.provenance_service
                _ = self.quality_service
            except:
                services_healthy = False
        healthy = et_available and services_healthy
        return ToolResult(
            tool_id=self.tool_id,
            status="success" if healthy else "error",
            data={
                "healthy": healthy,
                "elementtree_available": et_available,
                "services_healthy": services_healthy,
                "supported_formats": [".xml", ".xhtml", ".svg", ".rss", ".atom"],
                "status": self.status.value
            },
            metadata={
                "timestamp": datetime.now().isoformat()
            },
            execution_time=0.0,
            memory_used=0
        )
    def validate_input(self, input_data: Any) -> bool:
        """Validate input against tool contract with XML-specific validation"""
        # Call base validation first
        if not super().validate_input(input_data):
            return False
        # Additional validation for XML loader
        if isinstance(input_data, dict):
            file_path = input_data.get("file_path")
            if not file_path or not file_path.strip():
                return False
        return True
    def cleanup(self) -> bool:
        """Clean up any temporary files"""
        try:
            # Clean up temp files if any
            for temp_file in self._temp_files:
                try:
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                except:
                    pass
            self._temp_files = []
            self.status = ToolStatus.READY
            return True
        except Exception as e:
            logger.error(f"Cleanup failed: {e}")
            return False
</file>

<file path="src/tools/phase1/t11_powerpoint_loader_unified.py">
"""
T11: PowerPoint Document Loader - Unified Interface Implementation
Loads and parses PowerPoint documents (.pptx, .ppt) with comprehensive content extraction.
"""
from typing import Dict, Any, Optional, List, Union
import os
from pathlib import Path
import uuid
from datetime import datetime
import logging
from src.tools.base_tool import BaseTool, ToolRequest, ToolResult, ToolContract, ToolStatus, ToolErrorCode
from src.core.service_manager import ServiceManager
from src.core.advanced_data_models import Document, ObjectType, QualityTier
try:
    from pptx import Presentation
    from pptx.enum.shapes import MSO_SHAPE_TYPE
    PPTX_AVAILABLE = True
except ImportError:
    PPTX_AVAILABLE = False
logger = logging.getLogger(__name__)
class T11PowerPointLoaderUnified(BaseTool):
    """T11: PowerPoint Document Loader with unified interface"""
    def __init__(self, service_manager: ServiceManager):
        """Initialize with service manager"""
        super().__init__(service_manager)
        self.tool_id = "T11"
        self.identity_service = service_manager.identity_service
        self.provenance_service = service_manager.provenance_service
        self.quality_service = service_manager.quality_service
        self._temp_files = []
    def get_contract(self) -> ToolContract:
        """Return tool contract specification"""
        return ToolContract(
            tool_id=self.tool_id,
            name="PowerPoint Document Loader",
            description="Load and parse PowerPoint documents with comprehensive content extraction",
            category="document_processing",
            input_schema={
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "Path to PowerPoint file to load"
                    },
                    "workflow_id": {
                        "type": "string",
                        "description": "Optional workflow ID for tracking"
                    },
                    "parse_options": {
                        "type": "object",
                        "properties": {
                            "extract_images": {"type": "boolean", "default": False},
                            "extract_notes": {"type": "boolean", "default": True},
                            "extract_metadata": {"type": "boolean", "default": True},
                            "include_hidden_slides": {"type": "boolean", "default": False}
                        },
                        "default": {}
                    }
                },
                "required": ["file_path"]
            },
            output_schema={
                "type": "object",
                "properties": {
                    "document": {
                        "type": "object",
                        "properties": {
                            "document_id": {"type": "string"},
                            "document_ref": {"type": "string"},
                            "file_path": {"type": "string"},
                            "file_name": {"type": "string"},
                            "file_size": {"type": "integer"},
                            "presentation_data": {"type": "object"},
                            "text_content": {"type": "string"},
                            "slide_count": {"type": "integer"},
                            "shape_count": {"type": "integer"},
                            "confidence": {"type": "number"},
                            "quality_tier": {"type": "string"},
                            "created_at": {"type": "string"}
                        },
                        "required": ["document_id", "presentation_data", "text_content", "confidence", "slide_count"]
                    }
                },
                "required": ["document"]
            },
            dependencies=["identity_service", "provenance_service", "quality_service"],
            performance_requirements={
                "max_execution_time": 90.0,   # 90 seconds for large presentations
                "max_memory_mb": 1024,        # 1GB for PowerPoint processing
                "min_confidence": 0.8         # Minimum confidence threshold
            },
            error_conditions=[
                "FILE_NOT_FOUND",
                "INVALID_FILE_TYPE",
                "POWERPOINT_CORRUPTED",
                "POWERPOINT_PASSWORD_PROTECTED",
                "PPTX_LIBRARY_MISSING",
                "MEMORY_LIMIT_EXCEEDED"
            ]
        )
    def execute(self, request: ToolRequest) -> ToolResult:
        """Execute PowerPoint loading with unified interface"""
        self._start_execution()
        try:
            # Check if python-pptx is available
            if not PPTX_AVAILABLE:
                return self._create_error_result(
                    request,
                    "PPTX_LIBRARY_MISSING",
                    "python-pptx library is not installed. Install with: pip install python-pptx"
                )
            # Validate input
            if not self.validate_input(request.input_data):
                return self._create_error_result(
                    request,
                    "INVALID_INPUT",
                    "Input validation failed. Required: file_path"
                )
            # Extract parameters
            file_path = request.input_data.get("file_path")
            workflow_id = request.input_data.get("workflow_id")
            parse_options = request.input_data.get("parse_options", {})
            # Set default parse options
            parse_options = {
                "extract_images": parse_options.get("extract_images", False),
                "extract_notes": parse_options.get("extract_notes", True),
                "extract_metadata": parse_options.get("extract_metadata", True),
                "include_hidden_slides": parse_options.get("include_hidden_slides", False)
            }
            # Validate file path
            validation_result = self._validate_file_path(file_path)
            if not validation_result["valid"]:
                return self._create_error_result(
                    request,
                    validation_result["error_code"],
                    validation_result["error_message"]
                )
            file_path = Path(file_path)
            # Start provenance tracking
            operation_id = self.provenance_service.start_operation(
                tool_id=self.tool_id,
                operation_type="load_powerpoint_document",
                used={},
                parameters={
                    "file_path": str(file_path),
                    "workflow_id": workflow_id,
                    "parse_options": parse_options
                }
            )
            # Generate workflow ID if not provided
            if not workflow_id:
                workflow_id = f"wf_{uuid.uuid4().hex[:8]}"
            # Create document ID
            document_id = f"{workflow_id}_{file_path.stem}"
            document_ref = f"storage://document/{document_id}"
            # Parse PowerPoint document
            parsing_result = self._parse_powerpoint_document(file_path, parse_options)
            if parsing_result["status"] != "success":
                return self._create_error_result(
                    request,
                    parsing_result.get("error_code", "POWERPOINT_PARSE_ERROR"),
                    parsing_result["error"]
                )
            # Calculate confidence
            confidence = self._calculate_confidence(
                presentation_data=parsing_result["presentation_data"],
                slide_count=parsing_result["slide_count"],
                shape_count=parsing_result["shape_count"],
                file_size=file_path.stat().st_size
            )
            # Create document data
            document_data = {
                "document_id": document_id,
                "document_ref": document_ref,
                "file_path": str(file_path),
                "file_name": file_path.name,
                "file_size": file_path.stat().st_size,
                "presentation_data": parsing_result["presentation_data"],
                "text_content": parsing_result["text_content"],
                "slide_count": parsing_result["slide_count"],
                "shape_count": parsing_result["shape_count"],
                "confidence": confidence,
                "created_at": datetime.now().isoformat(),
                "tool_version": "1.0.0",
                "parse_options": parse_options
            }
            # Assess quality
            quality_result = self.quality_service.assess_confidence(
                object_ref=document_ref,
                base_confidence=confidence,
                factors={
                    "slide_count": min(1.0, parsing_result["slide_count"] / 50),
                    "shape_count": min(1.0, parsing_result["shape_count"] / 200),
                    "file_size": min(1.0, file_path.stat().st_size / (50 * 1024 * 1024)),
                    "content_richness": min(1.0, len(parsing_result["text_content"]) / 10000)
                },
                metadata={
                    "powerpoint_type": "presentation",
                    "parse_method": "python-pptx"
                }
            )
            if quality_result["status"] == "success":
                document_data["confidence"] = quality_result["confidence"]
                document_data["quality_tier"] = quality_result["quality_tier"]
            # Complete provenance
            self.provenance_service.complete_operation(
                operation_id=operation_id,
                outputs=[document_ref],
                success=True,
                metadata={
                    "slide_count": parsing_result["slide_count"],
                    "shape_count": parsing_result["shape_count"],
                    "text_length": len(parsing_result["text_content"]),
                    "confidence": document_data["confidence"]
                }
            )
            # Get execution metrics
            execution_time, memory_used = self._end_execution()
            # Create success result
            return ToolResult(
                tool_id=self.tool_id,
                status="success",
                data={
                    "document": document_data
                },
                metadata={
                    "operation_id": operation_id,
                    "workflow_id": workflow_id,
                    "parse_method": "python-pptx",
                    "parse_options": parse_options
                },
                execution_time=execution_time,
                memory_used=memory_used
            )
        except Exception as e:
            logger.error(f"Unexpected error in {self.tool_id}: {e}", exc_info=True)
            return self._create_error_result(
                request,
                "UNEXPECTED_ERROR",
                f"Unexpected error during PowerPoint loading: {str(e)}"
            )
    def _validate_file_path(self, file_path: str) -> Dict[str, Any]:
        """Validate file path for security and existence"""
        if not file_path:
            return {
                "valid": False,
                "error_code": "INVALID_INPUT",
                "error_message": "File path cannot be empty"
            }
        try:
            path = Path(file_path)
            # Check if path exists
            if not path.exists():
                return {
                    "valid": False,
                    "error_code": "FILE_NOT_FOUND",
                    "error_message": f"File not found: {file_path}"
                }
            # Check if it's a file
            if not path.is_file():
                return {
                    "valid": False,
                    "error_code": "INVALID_INPUT",
                    "error_message": f"Path is not a file: {file_path}"
                }
            # Check extension
            allowed_extensions = ['.pptx', '.ppt']
            if path.suffix.lower() not in allowed_extensions:
                return {
                    "valid": False,
                    "error_code": "INVALID_FILE_TYPE",
                    "error_message": f"Invalid file extension. Allowed: {allowed_extensions}"
                }
            # Basic security check - prevent path traversal
            if ".." in str(path) or str(path).startswith("/etc"):
                return {
                    "valid": False,
                    "error_code": "VALIDATION_FAILED",
                    "error_message": "Invalid file path"
                }
            return {"valid": True}
        except Exception as e:
            return {
                "valid": False,
                "error_code": "VALIDATION_FAILED",
                "error_message": f"Path validation failed: {str(e)}"
            }
    def _parse_powerpoint_document(self, file_path: Path, parse_options: Dict[str, Any]) -> Dict[str, Any]:
        """Parse PowerPoint document using python-pptx"""
        try:
            # Load presentation
            presentation = Presentation(file_path)
            # Extract presentation metadata
            metadata = {}
            if parse_options.get("extract_metadata", True):
                core_props = presentation.core_properties
                metadata = {
                    "title": getattr(core_props, 'title', None),
                    "author": getattr(core_props, 'author', None),
                    "subject": getattr(core_props, 'subject', None),
                    "keywords": getattr(core_props, 'keywords', None),
                    "category": getattr(core_props, 'category', None),
                    "comments": getattr(core_props, 'comments', None),
                    "created": getattr(core_props, 'created', None),
                    "modified": getattr(core_props, 'modified', None),
                    "last_modified_by": getattr(core_props, 'last_modified_by', None)
                }
                # Convert datetime objects to strings
                for key, value in metadata.items():
                    if hasattr(value, 'isoformat'):
                        metadata[key] = value.isoformat()
            # Extract slides data
            slides_data = []
            text_content_parts = []
            total_shape_count = 0
            for slide_idx, slide in enumerate(presentation.slides):
                slide_data = {
                    "slide_number": slide_idx + 1,
                    "shapes": [],
                    "notes": None,
                    "text_content": ""
                }
                # Extract shapes and text
                slide_text_parts = []
                shape_count = 0
                for shape in slide.shapes:
                    shape_count += 1
                    shape_info = {
                        "shape_type": str(shape.shape_type),
                        "text": None,
                        "has_text": False
                    }
                    # Extract text from shape
                    if hasattr(shape, "text") and shape.text:
                        shape_info["text"] = shape.text
                        shape_info["has_text"] = True
                        slide_text_parts.append(shape.text)
                    # Handle tables
                    if shape.shape_type == MSO_SHAPE_TYPE.TABLE:
                        table_text = self._extract_table_text(shape.table)
                        if table_text:
                            shape_info["table_text"] = table_text
                            slide_text_parts.append(table_text)
                    slide_data["shapes"].append(shape_info)
                slide_data["shape_count"] = shape_count
                total_shape_count += shape_count
                # Extract slide notes
                if parse_options.get("extract_notes", True):
                    try:
                        if slide.notes_slide and slide.notes_slide.notes_text_frame:
                            notes_text = slide.notes_slide.notes_text_frame.text
                            if notes_text.strip():
                                slide_data["notes"] = notes_text
                                slide_text_parts.append(f"Notes: {notes_text}")
                    except:
                        pass  # Notes extraction might fail for some slides
                # Combine slide text
                slide_text = " ".join(slide_text_parts)
                slide_data["text_content"] = slide_text
                if slide_text.strip():
                    text_content_parts.append(f"Slide {slide_idx + 1}: {slide_text}")
                slides_data.append(slide_data)
            # Combine all text content
            text_content = "\n\n".join(text_content_parts)
            # Create presentation data
            presentation_data = {
                "metadata": metadata,
                "slides": slides_data,
                "slide_count": len(presentation.slides),
                "total_shape_count": total_shape_count
            }
            return {
                "status": "success",
                "presentation_data": presentation_data,
                "text_content": text_content,
                "slide_count": len(presentation.slides),
                "shape_count": total_shape_count
            }
        except Exception as e:
            error_msg = str(e)
            if "password" in error_msg.lower() or "protected" in error_msg.lower():
                return {
                    "status": "error",
                    "error": f"PowerPoint file is password protected: {error_msg}",
                    "error_code": "POWERPOINT_PASSWORD_PROTECTED"
                }
            else:
                logger.error(f"Failed to parse PowerPoint document: {error_msg}")
                return {
                    "status": "error",
                    "error": f"Failed to parse PowerPoint document: {error_msg}",
                    "error_code": "POWERPOINT_CORRUPTED"
                }
    def _extract_table_text(self, table) -> str:
        """Extract text from a PowerPoint table"""
        try:
            table_text_parts = []
            for row in table.rows:
                row_text = []
                for cell in row.cells:
                    if cell.text:
                        row_text.append(cell.text.strip())
                if row_text:
                    table_text_parts.append(" | ".join(row_text))
            return "\n".join(table_text_parts)
        except:
            return ""
    def _calculate_confidence(self, presentation_data: Dict[str, Any], slide_count: int, 
                            shape_count: int, file_size: int) -> float:
        """Calculate confidence score for PowerPoint parsing"""
        base_confidence = 0.9  # High confidence for successful PowerPoint parsing
        # Factors that affect confidence
        factors = []
        # Slide count factor
        if slide_count > 20:
            factors.append(0.95)
        elif slide_count > 5:
            factors.append(0.9)
        elif slide_count > 1:
            factors.append(0.85)
        else:
            factors.append(0.8)
        # Shape count factor (content richness)
        if shape_count > 100:
            factors.append(0.95)
        elif shape_count > 20:
            factors.append(0.9)
        elif shape_count > 5:
            factors.append(0.85)
        else:
            factors.append(0.8)
        # File size factor
        if file_size > 10 * 1024 * 1024:  # > 10MB
            factors.append(0.95)
        elif file_size > 1024 * 1024:  # > 1MB
            factors.append(0.9)
        else:
            factors.append(0.85)
        # Content quality factor
        has_meaningful_content = False
        for slide in presentation_data.get("slides", []):
            if slide.get("text_content", "").strip():
                has_meaningful_content = True
                break
        if has_meaningful_content:
            factors.append(0.95)
        else:
            factors.append(0.7)
        # Calculate average
        if factors:
            final_confidence = sum([base_confidence] + factors) / (len(factors) + 1)
        else:
            final_confidence = base_confidence
        # Ensure confidence is in valid range
        return max(0.1, min(1.0, final_confidence))
    def validate_input(self, input_data: Any) -> bool:
        """Validate input against tool contract with PowerPoint-specific validation"""
        # Call base validation first
        if not super().validate_input(input_data):
            return False
        # Additional validation for PowerPoint loader
        if isinstance(input_data, dict):
            file_path = input_data.get("file_path")
            if not file_path or not file_path.strip():
                return False
        return True
    def health_check(self) -> ToolResult:
        """Check tool health and readiness"""
        try:
            # Check if python-pptx is available
            if PPTX_AVAILABLE:
                from pptx import __version__ as pptx_version
                pptx_available = True
            else:
                pptx_version = 'not_installed'
                pptx_available = False
        except:
            pptx_available = False
            pptx_version = 'unknown'
        # Check service dependencies
        services_healthy = True
        if self.services:
            try:
                # Basic check that services exist
                _ = self.identity_service
                _ = self.provenance_service
                _ = self.quality_service
            except:
                services_healthy = False
        healthy = pptx_available and services_healthy
        return ToolResult(
            tool_id=self.tool_id,
            status="success" if healthy else "error",
            data={
                "healthy": healthy,
                "pptx_available": pptx_available,
                "pptx_version": pptx_version,
                "services_healthy": services_healthy,
                "supported_formats": [".pptx", ".ppt"],
                "status": self.status.value
            },
            metadata={
                "timestamp": datetime.now().isoformat()
            },
            execution_time=0.0,
            memory_used=0
        )
    def cleanup(self) -> bool:
        """Clean up any temporary files"""
        try:
            # Clean up temp files if any
            for temp_file in self._temp_files:
                try:
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                except:
                    pass
            self._temp_files = []
            self.status = ToolStatus.READY
            return True
        except Exception as e:
            logger.error(f"Cleanup failed: {e}")
            return False
</file>

<file path="tests/unit/test_t11_powerpoint_loader_unified.py">
"""
Mock-free unit tests for T11 PowerPoint Loader Unified
Tests the unified PowerPoint loader tool with real PowerPoint processing using python-pptx.
No mocking is used - all functionality is tested with real data and real processing.
"""
import pytest
import tempfile
from pathlib import Path
import os
from src.tools.phase1.t11_powerpoint_loader_unified import T11PowerPointLoaderUnified
from src.core.service_manager import ServiceManager
from src.tools.base_tool import ToolRequest
try:
    from pptx import Presentation
    from pptx.util import Inches
    PPTX_AVAILABLE = True
except ImportError:
    PPTX_AVAILABLE = False
class TestT11PowerPointLoaderUnifiedMockFree:
    def setup_method(self):
        """Set up test fixtures with real ServiceManager - NO mocks"""
        # Real ServiceManager - NO mocking
        self.service_manager = ServiceManager()
        self.tool = T11PowerPointLoaderUnified(service_manager=self.service_manager)
        # Create real test PowerPoint files if python-pptx is available
        if PPTX_AVAILABLE:
            self.test_files = self._create_real_test_powerpoint_files()
        else:
            self.test_files = {}
    def teardown_method(self):
        """Clean up real test files"""
        for file_path in self.test_files.values():
            try:
                if os.path.exists(file_path):
                    os.unlink(file_path)
            except:
                pass
    def _create_real_test_powerpoint_files(self) -> dict:
        """Create real PowerPoint test files for testing"""
        test_files = {}
        # Skip if python-pptx not available
        if not PPTX_AVAILABLE:
            return test_files
        # Simple PowerPoint with text content
        prs_simple = Presentation()
        # Title slide
        title_slide_layout = prs_simple.slide_layouts[0]
        slide = prs_simple.slides.add_slide(title_slide_layout)
        title = slide.shapes.title
        subtitle = slide.placeholders[1]
        title.text = "Test Presentation"
        subtitle.text = "Created for unit testing"
        # Content slide
        bullet_slide_layout = prs_simple.slide_layouts[1]
        slide = prs_simple.slides.add_slide(bullet_slide_layout)
        shapes = slide.shapes
        title_shape = shapes.title
        body_shape = shapes.placeholders[1]
        title_shape.text = 'Key Features'
        tf = body_shape.text_frame
        tf.text = 'Feature 1: Document loading'
        p = tf.add_paragraph()
        p.text = 'Feature 2: Text extraction'
        p = tf.add_paragraph()
        p.text = 'Feature 3: Content analysis'
        simple_file = tempfile.NamedTemporaryFile(suffix='.pptx', delete=False)
        prs_simple.save(simple_file.name)
        simple_file.close()
        test_files['simple'] = simple_file.name
        # Complex PowerPoint with multiple slide types
        prs_complex = Presentation()
        # Title slide
        title_slide = prs_complex.slides.add_slide(prs_complex.slide_layouts[0])
        title_slide.shapes.title.text = "Complex Presentation"
        title_slide.placeholders[1].text = "Advanced Testing Scenarios"
        # Content with bullet points
        content_slide = prs_complex.slides.add_slide(prs_complex.slide_layouts[1])
        content_slide.shapes.title.text = "Project Overview"
        tf = content_slide.shapes.placeholders[1].text_frame
        tf.text = "Objective: Implement mock-free testing"
        p = tf.add_paragraph()
        p.text = "Approach: Real library integration"
        p = tf.add_paragraph()
        p.text = "Result: High confidence validation"
        # Blank slide with custom content
        blank_slide = prs_complex.slides.add_slide(prs_complex.slide_layouts[6])
        textbox = blank_slide.shapes.add_textbox(Inches(1), Inches(1), Inches(4), Inches(2))
        textbox.text_frame.text = "Custom textbox content for testing"
        # Another content slide
        final_slide = prs_complex.slides.add_slide(prs_complex.slide_layouts[1])
        final_slide.shapes.title.text = "Conclusion"
        tf = final_slide.shapes.placeholders[1].text_frame
        tf.text = "Testing methodology validated"
        p = tf.add_paragraph()
        p.text = "Real functionality confirmed"
        complex_file = tempfile.NamedTemporaryFile(suffix='.pptx', delete=False)
        prs_complex.save(complex_file.name)
        complex_file.close()
        test_files['complex'] = complex_file.name
        return test_files
    @pytest.mark.skipif(not PPTX_AVAILABLE, reason="python-pptx not available")
    def test_tool_contract_real(self):
        """Test tool contract with REAL contract validation"""
        contract = self.tool.get_contract()
        # Verify contract structure
        assert contract.tool_id == "T11"
        assert contract.name == "PowerPoint Document Loader"
        assert contract.category == "document_processing"
        assert "file_path" in contract.input_schema["required"]
        assert "document" in contract.output_schema["required"]
        assert len(contract.dependencies) > 0
        # Verify performance requirements
        assert "max_execution_time" in contract.performance_requirements
        assert "max_memory_mb" in contract.performance_requirements
        assert "min_confidence" in contract.performance_requirements
        # Verify error conditions
        assert "POWERPOINT_CORRUPTED" in contract.error_conditions
        assert "FILE_NOT_FOUND" in contract.error_conditions
    @pytest.mark.skipif(not PPTX_AVAILABLE, reason="python-pptx not available")
    def test_simple_powerpoint_loading_real(self):
        """Test loading simple PowerPoint with REAL processing"""
        request = ToolRequest(
            tool_id="T11",
            operation="load_powerpoint",
            input_data={
                "file_path": self.test_files['simple'],
                "workflow_id": "test_workflow_simple"
            },
            parameters={}
        )
        result = self.tool.execute(request)
        # Verify successful execution
        assert result.status == "success"
        assert result.tool_id == "T11"
        assert result.execution_time > 0
        # Verify document data
        doc = result.data["document"]
        assert doc["document_id"] == "test_workflow_simple_" + Path(self.test_files['simple']).stem
        assert doc["file_name"] == Path(self.test_files['simple']).name
        assert doc["slide_count"] == 2  # Title + content slide
        assert doc["shape_count"] > 0
        assert doc["confidence"] > 0.5
        assert len(doc["text_content"]) > 0
        # Verify presentation data structure
        presentation_data = doc["presentation_data"]
        assert "slides" in presentation_data
        assert "metadata" in presentation_data
        assert len(presentation_data["slides"]) == 2
        # Verify specific content
        assert "Test Presentation" in doc["text_content"]
        assert "Key Features" in doc["text_content"]
        assert "Feature 1" in doc["text_content"]
    @pytest.mark.skipif(not PPTX_AVAILABLE, reason="python-pptx not available")
    def test_complex_powerpoint_multiple_slides_real(self):
        """Test loading complex PowerPoint with multiple slides with REAL processing"""
        request = ToolRequest(
            tool_id="T11",
            operation="load_powerpoint",
            input_data={
                "file_path": self.test_files['complex'],
                "workflow_id": "test_workflow_complex"
            },
            parameters={}
        )
        result = self.tool.execute(request)
        # Verify successful execution
        assert result.status == "success"
        # Verify document data
        doc = result.data["document"]
        assert doc["slide_count"] == 4  # Title + content + blank + final
        assert doc["shape_count"] > 5   # Multiple shapes across slides
        assert doc["confidence"] > 0.5
        # Verify presentation data
        presentation_data = doc["presentation_data"]
        assert len(presentation_data["slides"]) == 4
        # Verify content from all slides
        assert "Complex Presentation" in doc["text_content"]      # Title slide
        assert "Project Overview" in doc["text_content"]         # Content slide
        assert "Custom textbox content" in doc["text_content"]   # Blank slide
        assert "Conclusion" in doc["text_content"]              # Final slide
    @pytest.mark.skipif(not PPTX_AVAILABLE, reason="python-pptx not available")
    def test_parse_options_functionality_real(self):
        """Test different parse options with REAL processing"""
        # Test with metadata extraction enabled
        request_metadata = ToolRequest(
            tool_id="T11",
            operation="load_powerpoint",
            input_data={
                "file_path": self.test_files['simple'],
                "parse_options": {
                    "extract_metadata": True,
                    "extract_notes": True
                }
            },
            parameters={}
        )
        result_metadata = self.tool.execute(request_metadata)
        assert result_metadata.status == "success"
        # Verify metadata is included
        presentation_data = result_metadata.data["document"]["presentation_data"]
        assert "metadata" in presentation_data
        # Test with metadata extraction disabled
        request_no_metadata = ToolRequest(
            tool_id="T11",
            operation="load_powerpoint",
            input_data={
                "file_path": self.test_files['simple'],
                "parse_options": {
                    "extract_metadata": False
                }
            },
            parameters={}
        )
        result_no_metadata = self.tool.execute(request_no_metadata)
        assert result_no_metadata.status == "success"
    def test_file_not_found_error_real(self):
        """Test file not found error with REAL missing file"""
        request = ToolRequest(
            tool_id="T11",
            operation="load_powerpoint",
            input_data={
                "file_path": "/path/to/nonexistent/file.pptx"
            },
            parameters={}
        )
        result = self.tool.execute(request)
        # Verify error handling
        assert result.status == "error"
        assert result.error_code == "FILE_NOT_FOUND"
        assert "File not found" in result.error_message
    def test_invalid_file_type_error_real(self):
        """Test invalid file type error with REAL non-PowerPoint file"""
        # Create a non-PowerPoint file
        txt_file = tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False)
        txt_file.write("This is not a PowerPoint file")
        txt_file.close()
        try:
            request = ToolRequest(
                tool_id="T11",
                operation="load_powerpoint",
                input_data={
                    "file_path": txt_file.name
                },
                parameters={}
            )
            result = self.tool.execute(request)
            # Verify error handling
            assert result.status == "error"
            assert result.error_code == "INVALID_FILE_TYPE"
            assert "Invalid file extension" in result.error_message
        finally:
            os.unlink(txt_file.name)
    def test_library_not_available_error_real(self):
        """Test behavior when python-pptx library is not available"""
        # This test simulates the library not being available
        # by temporarily setting PPTX_AVAILABLE to False in the tool
        original_available = self.tool.__class__.__module__ 
        # Create a request
        request = ToolRequest(
            tool_id="T11",
            operation="load_powerpoint",
            input_data={
                "file_path": "/some/file.pptx"
            },
            parameters={}
        )
        # If python-pptx is not available, should get library missing error
        if not PPTX_AVAILABLE:
            result = self.tool.execute(request)
            assert result.status == "error"
            assert result.error_code == "PPTX_LIBRARY_MISSING"
    def test_input_validation_real(self):
        """Test input validation with REAL validation logic"""
        # Test missing file_path
        result = self.tool.validate_input({})
        assert result == False
        result = self.tool.validate_input({"file_path": ""})
        assert result == False
        # Test valid input
        result = self.tool.validate_input({"file_path": "/some/path.pptx"})
        assert result == True
    def test_health_check_real(self):
        """Test health check with REAL service verification"""
        result = self.tool.health_check()
        # Verify health check structure
        assert isinstance(result.data, dict)
        assert "healthy" in result.data
        assert "pptx_available" in result.data
        assert "services_healthy" in result.data
        assert "supported_formats" in result.data
        # Verify supported formats
        supported_formats = result.data["supported_formats"]
        assert ".pptx" in supported_formats
        assert ".ppt" in supported_formats
    def test_cleanup_functionality_real(self):
        """Test cleanup functionality with REAL resource management"""
        # Add some temp files to the tool
        temp_file = tempfile.NamedTemporaryFile(delete=False)
        temp_file.close()
        self.tool._temp_files.append(temp_file.name)
        # Verify cleanup works
        cleanup_result = self.tool.cleanup()
        assert cleanup_result == True
        assert len(self.tool._temp_files) == 0
        assert not os.path.exists(temp_file.name)
    @pytest.mark.skipif(not PPTX_AVAILABLE, reason="python-pptx not available")
    def test_confidence_calculation_real(self):
        """Test confidence calculation with REAL PowerPoint parsing metrics"""
        # Test with simple PowerPoint
        request_simple = ToolRequest(
            tool_id="T11",
            operation="load_powerpoint",
            input_data={"file_path": self.test_files['simple']},
            parameters={}
        )
        result_simple = self.tool.execute(request_simple)
        confidence_simple = result_simple.data["document"]["confidence"]
        # Test with complex PowerPoint
        request_complex = ToolRequest(
            tool_id="T11",
            operation="load_powerpoint",
            input_data={"file_path": self.test_files['complex']},
            parameters={}
        )
        result_complex = self.tool.execute(request_complex)
        confidence_complex = result_complex.data["document"]["confidence"]
        # Both should have reasonable confidence
        assert confidence_simple > 0.5
        assert confidence_complex > 0.5
        # Complex PowerPoint should have higher confidence due to more content
        assert confidence_complex >= confidence_simple - 0.1
    @pytest.mark.skipif(not PPTX_AVAILABLE, reason="python-pptx not available")
    def test_performance_metrics_real(self):
        """Test performance metrics with REAL execution measurement"""
        request = ToolRequest(
            tool_id="T11",
            operation="load_powerpoint",
            input_data={"file_path": self.test_files['complex']},
            parameters={}
        )
        result = self.tool.execute(request)
        # Verify performance metrics are captured
        assert result.execution_time > 0
        assert result.memory_used >= 0
        # Verify reasonable execution time
        assert result.execution_time < 5.0  # Should be under 5 seconds
    @pytest.mark.skipif(not PPTX_AVAILABLE, reason="python-pptx not available")
    def test_service_integration_real(self):
        """Test service integration with REAL services"""
        request = ToolRequest(
            tool_id="T11",
            operation="load_powerpoint",
            input_data={
                "file_path": self.test_files['simple'],
                "workflow_id": "test_service_integration"
            },
            parameters={}
        )
        result = self.tool.execute(request)
        # Verify service integration
        assert result.status == "success"
        assert "operation_id" in result.metadata
        # Verify provenance tracking
        operation_id = result.metadata["operation_id"]
        assert operation_id is not None
        # Verify quality assessment
        doc = result.data["document"]
        assert "quality_tier" in doc
        assert doc["confidence"] > 0
    @pytest.mark.skipif(not PPTX_AVAILABLE, reason="python-pptx not available")
    def test_slide_content_extraction_real(self):
        """Test slide content extraction with REAL PowerPoint parsing"""
        request = ToolRequest(
            tool_id="T11",
            operation="load_powerpoint",
            input_data={"file_path": self.test_files['complex']},
            parameters={}
        )
        result = self.tool.execute(request)
        presentation_data = result.data["document"]["presentation_data"]
        # Verify slide structure
        slides = presentation_data["slides"]
        assert len(slides) == 4
        # Verify each slide has expected structure
        for slide in slides:
            assert "slide_number" in slide
            assert "shapes" in slide
            assert "text_content" in slide
            assert isinstance(slide["shapes"], list)
        # Verify specific slide content
        slide_texts = [slide["text_content"] for slide in slides]
        combined_text = " ".join(slide_texts)
        assert "Complex Presentation" in combined_text
        assert "Project Overview" in combined_text
    @pytest.mark.skipif(not PPTX_AVAILABLE, reason="python-pptx not available")
    def test_text_content_extraction_real(self):
        """Test text content extraction with REAL text processing"""
        request = ToolRequest(
            tool_id="T11",
            operation="load_powerpoint",
            input_data={"file_path": self.test_files['simple']},
            parameters={}
        )
        result = self.tool.execute(request)
        text_content = result.data["document"]["text_content"]
        # Verify all expected content is extracted
        assert "Test Presentation" in text_content
        assert "Created for unit testing" in text_content
        assert "Key Features" in text_content
        assert "Feature 1: Document loading" in text_content
        assert "Feature 2: Text extraction" in text_content
        # Verify text is properly formatted
        assert len(text_content.strip()) > 0
        lines = text_content.split('\n')
        assert len(lines) > 1  # Should have multiple lines of content
    @pytest.mark.skipif(not PPTX_AVAILABLE, reason="python-pptx not available")
    def test_shape_counting_real(self):
        """Test shape counting with REAL PowerPoint analysis"""
        request = ToolRequest(
            tool_id="T11",
            operation="load_powerpoint",
            input_data={"file_path": self.test_files['complex']},
            parameters={}
        )
        result = self.tool.execute(request)
        doc = result.data["document"]
        # Verify shape counting
        assert doc["shape_count"] > 0
        # Verify shape details in presentation data
        presentation_data = doc["presentation_data"]
        total_shapes = 0
        for slide in presentation_data["slides"]:
            total_shapes += slide["shape_count"]
        # Total should match document shape count
        assert total_shapes == doc["shape_count"]
</file>

<file path="src/tools/base_tool.py">
"""
Base Tool Infrastructure for Unified Tool Interface
Provides the contract-first design for all KGAS tools.
"""
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, field
from enum import Enum
import time
import psutil
from datetime import datetime
class ToolStatus(Enum):
    """Tool operational status"""
    READY = "ready"
    PROCESSING = "processing"
    ERROR = "error"
    MAINTENANCE = "maintenance"
class ToolErrorCode(Enum):
    """Standardized tool error codes for programmatic handling"""
    # Input/Validation Errors
    INVALID_INPUT = "INVALID_INPUT"
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    INVALID_FILE_TYPE = "INVALID_FILE_TYPE"
    VALIDATION_FAILED = "VALIDATION_FAILED"
    # Processing Errors
    PARSE_ERROR = "PARSE_ERROR"
    XML_MALFORMED = "XML_MALFORMED"
    XML_PARSE_ERROR = "XML_PARSE_ERROR"
    YAML_SYNTAX_ERROR = "YAML_SYNTAX_ERROR"
    YAML_PARSE_ERROR = "YAML_PARSE_ERROR"
    EXCEL_CORRUPTED = "EXCEL_CORRUPTED"
    EXCEL_PASSWORD_PROTECTED = "EXCEL_PASSWORD_PROTECTED"
    POWERPOINT_CORRUPTED = "POWERPOINT_CORRUPTED"
    POWERPOINT_PASSWORD_PROTECTED = "POWERPOINT_PASSWORD_PROTECTED"
    SHEET_NOT_FOUND = "SHEET_NOT_FOUND"
    # Library/Dependency Errors
    LIBRARY_MISSING = "LIBRARY_MISSING"
    PPTX_LIBRARY_MISSING = "PPTX_LIBRARY_MISSING"
    UNSAFE_YAML_CONTENT = "UNSAFE_YAML_CONTENT"
    NAMESPACE_ERROR = "NAMESPACE_ERROR"
    # System Errors
    MEMORY_LIMIT_EXCEEDED = "MEMORY_LIMIT_EXCEEDED"
    EXECUTION_TIMEOUT = "EXECUTION_TIMEOUT"
    HEALTH_CHECK_FAILED = "HEALTH_CHECK_FAILED"
    UNEXPECTED_ERROR = "UNEXPECTED_ERROR"
@dataclass(frozen=True)
class ToolRequest:
    """Standardized tool input format"""
    tool_id: str
    operation: str
    input_data: Any
    parameters: Dict[str, Any] = field(default_factory=dict)
    context: Optional[Dict[str, Any]] = field(default=None)
    validation_mode: bool = field(default=False)
@dataclass(frozen=True)
class ToolResult:
    """Standardized tool output format"""
    tool_id: str
    status: str  # "success" or "error"
    data: Any = field(default=None)
    metadata: Dict[str, Any] = field(default_factory=dict)
    execution_time: float = field(default=0.0)
    memory_used: int = field(default=0)
    error_code: Optional[str] = field(default=None)
    error_message: Optional[str] = field(default=None)
@dataclass(frozen=True)
class ToolContract:
    """Tool capability and requirement specification"""
    tool_id: str
    name: str
    description: str
    category: str  # "document_processing", "graph", "table", "vector", "cross_modal"
    input_schema: Dict[str, Any] = field(default_factory=dict)
    output_schema: Dict[str, Any] = field(default_factory=dict)
    dependencies: List[str] = field(default_factory=list)
    performance_requirements: Dict[str, Any] = field(default_factory=dict)
    error_conditions: List[str] = field(default_factory=list)
class BaseTool(ABC):
    """Base class all tools MUST inherit from"""
    def __init__(self, services):
        """Initialize with service manager"""
        self.services = services
        self.tool_id = self.__class__.__name__  # Override in subclass
        self.status = ToolStatus.READY
        self._start_time = None
        self._start_memory = None
    @abstractmethod
    def get_contract(self) -> ToolContract:
        """Return tool contract specification"""
        pass
    @abstractmethod
    def execute(self, request: ToolRequest) -> ToolResult:
        """Execute tool operation with standardized input/output"""
        pass
    def validate_input(self, input_data: Any) -> bool:
        """Validate input against tool contract"""
        # Basic implementation - override for specific validation
        if input_data is None:
            return False
        contract = self.get_contract()
        required_fields = contract.input_schema.get("required", [])
        if isinstance(input_data, dict):
            for field in required_fields:
                if field not in input_data:
                    return False
        return True
    def health_check(self) -> ToolResult:
        """Check tool health and readiness"""
        try:
            # Basic health check - override for specific checks
            healthy = self.status in [ToolStatus.READY, ToolStatus.PROCESSING]
            return ToolResult(
                tool_id=self.tool_id,
                status="success" if healthy else "error",
                data={
                    "healthy": healthy,
                    "status": self.status.value,
                    "contract": self.get_contract().name
                },
                metadata={
                    "timestamp": datetime.now().isoformat()
                },
                execution_time=0.0,
                memory_used=0
            )
        except Exception as e:
            return ToolResult(
                tool_id=self.tool_id,
                status="error",
                data={"healthy": False},
                metadata={"error": str(e)},
                execution_time=0.0,
                memory_used=0,
                error_code="HEALTH_CHECK_FAILED",
                error_message=str(e)
            )
    def get_status(self) -> ToolStatus:
        """Get current tool status"""
        return self.status
    def cleanup(self) -> bool:
        """Clean up tool resources"""
        # Basic cleanup - override for specific cleanup
        self.status = ToolStatus.READY
        return True
    def _start_execution(self):
        """Start execution tracking"""
        self._start_time = time.time()
        try:
            self._start_memory = psutil.Process().memory_info().rss
        except:
            self._start_memory = 0  # Fallback if psutil fails
        self.status = ToolStatus.PROCESSING
    def _end_execution(self) -> tuple:
        """End execution tracking and return metrics"""
        execution_time = time.time() - self._start_time if self._start_time else 0.0
        try:
            current_memory = psutil.Process().memory_info().rss
            memory_used = current_memory - self._start_memory if self._start_memory else 0
        except:
            memory_used = 0  # Fallback if psutil fails
        self.status = ToolStatus.READY
        return execution_time, memory_used
    def _create_error_result(self, request: ToolRequest, error_code: str, error_message: str) -> ToolResult:
        """Create standardized error result"""
        execution_time, memory_used = self._end_execution()
        self.status = ToolStatus.ERROR
        return ToolResult(
            tool_id=self.tool_id,
            status="error",
            data=None,
            metadata={
                "operation": request.operation,
                "timestamp": datetime.now().isoformat()
            },
            execution_time=execution_time,
            memory_used=memory_used,
            error_code=error_code,
            error_message=error_message
        )
</file>

</files>

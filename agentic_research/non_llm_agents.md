Comparison of Major Non-LLM AI Agent Types
Agent Type	Core Architecture/Formalism	Learning Paradigm	Cognitive Modeling	Strengths	Weaknesses	Typical Use Cases	Interpretability	Scalability	Real-Time Adaptability	Key Examples/Frameworks	Historical Context
Symbolic (GOFAI)	Logic/rule-based (first-order logic, semantic nets, frames)geeksforgeeks.org	None (hand-crafted rules/KBs)geeksforgeeks.org	Low (focus on formal reasoning)	Transparent, logical reasoninggeeksforgeeks.org; excels on structured expert tasks	Poor scalability (rule explosion)geeksforgeeks.org; brittle with ambiguity or novel datageeksforgeeks.org	Expert systems (medical diagnosis e.g. MYCINgeeksforgeeks.org, legal reasoning), symbolic planning	Very high (explicit rule trace)geeksforgeeks.org	Lowgeeksforgeeks.org (expands poorly)	Low (static knowledge; no online learning)geeksforgeeks.org	Prolog, CLIPS, Drools, MYCIN	Dominant in early AI (1950s–80s); declined with rise of ML in 1990sgeeksforgeeks.org; now used in neurosymbolic hybrids
Reactive/Behavioral (Subsumption)	Layered sensorimotor behaviors (augmented FSMs)en.wikipedia.org	None (predefined behaviors)	Very low (purely reactive)	Fast, robust real-time reactionen.wikipedia.orgen.wikipedia.org; decentralized parallel control	No memory or global modelen.wikipedia.org; cannot learn complex tasks or plan ahead	Mobile/robotic control (obstacle avoidance, navigation)	Moderate (simple rules are understandable)	Good (layers can be added)	Excellent (designed for immediate response)	Brooks’ subsumption robots	Introduced mid-1980s as “Nouvelle AI” alternative to symbolic AIen.wikipedia.org
BDI (Belief-Desire-Intention)	Modal logic model with explicit beliefs, desires (goals), intentionsen.wikipedia.org	None (architectural; plans are predefined)en.wikipedia.org	Moderate (models goal-driven behavior)	Natural goal/plan structure; clear “mental” state representation	No built-in learning or lookaheaden.wikipedia.org; requires complex plan libraries	Agent-oriented programming (virtual assistants, game AI, simulations)	High (internal states explicit)	Moderate (multi-agent settings)	Low (mainly deliberative/planned response)	PRS, JACK, AgentSpeak/Jason, 3APLen.wikipedia.org	Formalized in 1980s (Bratman et al.); still used in multi-agent systems and agent programming
Reinforcement Learning	Markov Decision Process (trial-and-error with reward)en.wikipedia.org	Yes (policy optimization via rewards)	Low (behaviorist learning)	Learns from interaction; handles sequential decision taskssynopsys.com	Data-intensive; slow (needs many trials)synopsys.com; often opaque decision rulessynopsys.com	Control systems, robotics, game AI (Atari, Go), resource management	Low (especially deep nets)synopsys.com	High (with function approximators, but compute-heavy)	Moderate (can adapt but needs retraining)	Q-learning, DQN, PPO, AlphaGo	Roots in 1950s psychology (trial-and-error); surged with deep RL breakthroughs in 2010s
Evolutionary Algorithms	Population-based search (genetic encodings, operators)larksuite.com	Yes (selection, crossover, mutation)	Low (evolutionary metaphor)	Robust global search; parallelizablelarksuite.com	Very compute-intensive (many evaluations)larksuite.com; convergence not guaranteed; parameter-sensitive	Optimization and design (scheduling, network/neural evolution)	Low (solutions are complex/genomic)	Moderate (scales with compute resources)	Low (batch/offline evolution)	Genetic Algorithms (GA), NEAT, CMA-ES	Developed 1960s–70s (Holland’s GA); widely used in optimization and creative design
Swarm Intelligence	Decentralized multi-agent (e.g. ant colony, particle swarm)en.wikipedia.org	No explicit learning (simple local rules)	Low (emergent group behavior)	Highly robust and scalable (many simple agents)larksuite.comen.wikipedia.org	Can prematurely converge; emergent results may be unpredictable	Distributed optimization (TSP, routing), swarm robotics, sensor networks	Moderate (agent rules are simple, global outcome complex)	High (adds agents)	Yes (agents act concurrently)	ACO (Ant Colony), PSO (Particle Swarm), Boids	Introduced 1989 by Beni & Wangen.wikipedia.org; popular for optimization and collective robotics
Planning (Symbolic)	Logic-based planning/search (STRIPS, PDDL)en.wikipedia.org	No (uses explicit domain model)	Low (algorithmic search)	Systematically finds action sequences; goal guarantees if model is correct	Requires complete model; combinatorial explosion; inflexible to surprises	Task sequencing in robotics, logistics, automated scheduling	High (plans are explicit)	Low (state space grows combinatorially)	Low (mostly offline planning)	STRIPS/GraphPlan, FastDownward, FF planner	Research since 1960s (Shakey); matured with 1990s PDDL standard; still used in robot/task planning
Hybrid Cognitive Architectures	Integrated symbolic/sub-symbolic architectures (e.g. ACT-R, Soar)en.wikipedia.org	Often includes learning (rule compilation, memory)	High (models human cognition)	Broad cognitive capabilities (reasoning, memory, learning)	Very complex; computationally heavy; limited real-time throughput	Cognitive modeling, intelligent tutoring, high-level agent control	Moderate (some modules inspectable)	Low (designed for cognitive fidelity)	Low (simulation-oriented)	Soar, ACT-R, CLARION, LIDA	Proposed 1980s–90s (Newell’s unified theory); active in AI and cognitive science research

Each agent type above is described by its core design and computational paradigm, along with how it learns (if at all) and whether it aims to mimic human-like cognition. Strengths and weaknesses are summarized, citing relevant literature. Interpretability refers to how easily a human can understand the agent’s decision process (with symbolic and BDI approaches being highly interpretable, and deep RL or evolved solutions generally less so). Scalability refers to practical performance on larger problems, and real-time adaptability indicates whether the agent can adjust on the fly (e.g. reactive/swarm agents excel here). Representative systems and historical notes illustrate each approach’s contextgeeksforgeeks.orggeeksforgeeks.orgsynopsys.comen.wikipedia.org.
Sources: Authoritative AI texts and surveys were used to compile this comparison (citations above include overviews of symbolic AIgeeksforgeeks.orggeeksforgeeks.org, RLsynopsys.comen.wikipedia.org, BDIen.wikipedia.orgen.wikipedia.org, evolutionary/swarm methodslarksuite.comen.wikipedia.org, planningen.wikipedia.org, and cognitive architecturesen.wikipedia.org). These sources discuss the formal models, capabilities, and historical evolution of each agent type.
